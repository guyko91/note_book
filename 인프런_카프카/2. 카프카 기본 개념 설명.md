
# 1. 오픈소스 아파치 카프카 생태계

![](./imgs/2-0.png)
* 기본적으로 카프카 클러스터가 있고, 목적에 따른 토픽들이 존재한다.
* 데이터를 넣는 역할을 하는 **'프로듀서' (Producer)**
* 데이터를 가져가는 **'컨슈머' (Consumer)**
* 토픽에 저장된 데이터를 재가공 해서 다른 토픽에 넣고 싶을 때 사용하는 **'스트림즈'**
* 원천 데이터를 가져오거나 타겟 저장소에 데이터를 저장할 떄 사용하는 **'커넥트'**
	* 소스 커넥트는 Producer 역할을 한다.
	* 싱크 커넥트는 Consumer 역할을 한다.
* Producer, Consumer, Streams, Connect 모두 카프카에서 공식적으로 오픈소스로 제공하는 java로 만들어진 라이브러리. (golang 등 다른 언어로 되어 있는 라이브러리들은 3rd party 이며, 호환성을 보장할 수 없다.)
---
# 2. 카프카 브로커와 클러스터
![](./imgs/2-1.png)
* 카프카 2.X 버전 까지는 주키퍼가 필수이지만, 3.X 버전 까지는 주키퍼가 필수가 아니다.
* 카프카 클러스터는 N 개의 브로커로 이루어져 있다.
	* 각 브로커는 하나의 물리적 서버 또는 인스턴스이다.
	* 보통 상용에서는 3개의 브로커를 운영한다. (많게는 50~100개까지)
* N개의 브로커는 데이터를 분산 저장하여 장애 발생시에도 안전하게 사용할 수 있도록 도와주기 때문에, 브로커는 최소 2~3개로 운영하는 것이 좋다.
---
# 3. 카프카 클러스터와 주키퍼
![](./imgs/2-3.png)
* 카프카 클러스터를 실행하기 위해서는 주키퍼가 필요하다.
* 여러개의 카프카 클러스트를 운영하는 경우가 있다.
	* 각 팀별로 다른 카프카 클러스터를 사용하는 경우 등.
	* 주키퍼 앙상블을 통해서 동시에 여러 카프카 클러스터를 운영할 수 있다.
		* 주키퍼 설정 시, root znode에 각 클러스터별 znode 를 생성하고, 클러스터 실행시 root 가 아닌 하위 znode 로 설정 한다.
---
# 4. 카프카 브로커의 역할

* 컨트롤러
	* 카프카 클러스터 내 N 개의 브로커 중 한대가 '컨트롤러' 역할을 한다.
	* 클러스터 내에는 리더 파티션과 팔로워 파티션이 존재하는데, 특정 브로커가 다운되면, 컨트롤러 브로커는 해당 down 된 브로커의 리더 파티션을 다른 브로커로 재분배한다.
	* 컨트롤러 브로커가 down 된 경우에는 다른 브로커가 컨트롤러 역할을 대신한다.
* 데이터 삭제
	* 카프카는 다른 메시징 플랫폼과 다르게, 컨슈머가 메시지를 소모해도 데이터가 삭제되지 않는다.
	* 카프카는 삭제를 파일 단위로 수행하는데 이 단위를 '로그 세그먼트' (log segment)라 불린다.
* 컨슈머 오프셋 저장
	* 토픽에 있는 데이터를 컨슈머가 가져갔을 때, 컨슈머는 본인이 데이터 어디까지 처리했는지를 commit 을 통해 브로커에게 알리는데, 브로커는 각 컨슈머가 어느 데이터 까지 처리했는지 offset 정보를 저장한다. 
	* commit 된 offset 데이터는 '**consumer_offsets**' 토픽에 저장된다. 카프카가 재구동 됐을때 컨슈머별로 어디까지 데이터를 처리 했는지를 확인할 수 있다.
* 그룹 코디네이터
	* 컨슈머 그룹의 상태를 체크하고 파티션을 컨슈머와 매칭되도록 분배하는 역할.
	* 특정 컨슈머가 컨슈머 그룹에서 빠지면 매칭되지 않은 파티션을 정상 동작하는 컨슈머로 할당하여 끊임 없이 데이터가 처리되도록 돕는다.
	* 컨슈머가 끊긴 파티션을 다시 살아있는 컨슈머로 재할당 하는 과정을 '**리밸런스**' 라고 한다.
* 데이터 저장
	* 카프카 실행 시, config/server.properties 의 **log.dir 옵션에 정의한 디렉토리**에 데이터를 저장한다.
		* **토픽 이름과 파티션 번호의 조합**으로 하위 디렉토리를 생성하여 데이터를 저장한다.
		* ![](./imgs/2-4.png)
		* hello.kafka 토픽의 0번 파티션에 존재하는 데이터를 확인할 수 있다.
		* .log 파일 : 메시지와 메타데이터를 담은 파일.
		* .index 파일 : 메시지의 오프셋을 인덱싱한 정보를 담은 파일.
		* .timeindex 파일 : 메시지에 포함된 timestamp 값을 기준으로 인덱싱한 정보를 담은 파일.
	* 로그와 세그먼트
		* log 가저장될 때, 하나의 파일에 모두 저장되는게 아니라, 바이트 단위 or 시간 단위로 파일이 새로 생성된다. 로그파일의 단위를 세그먼트라고 말한다. 
			* log.segment.bytes : 설정값에 도달 시 새로운 파일로 생성. (기본 값은 1GB)
			* log.roll.ms(hours) : 세그먼트가 신규 생성된 이후 다음 파일로 넘어가는 시간 주기 (기본값은 7일)
	* 액티브 세그먼트
		* 쓰기가 현지 발생하고 있는 파일 (마지막 로그 파일)
		* 액티브 세그먼트는 브로커의 삭제 대상에 포함되지 않는다.
		* 액티브 세그먼트가 아닌 나머지 세그먼트는 리텐션(retention)기간 옵션에 따라 대상으로 지정된다.
	* 세그먼트 삭제 관련 설정
		* cleanup.policy=delete
			* retention.ms(minutes, hours) : 세그먼트를 보유할 최대 기간 (기본 값 7일)
				* **디스크 여유 용량을 기준으로 고려해봐야 한다.** 
			* retention.bytes : 파티션 당 로그 적재 바이트 값 (기본 값 미지정 -1)
			* log.retention.check.interval.ms : 세그먼트가 삭제 영역에 들어왔는지 확인하는 간격 (기본 값 5분)
			* 유의사항
				* 카프카 데이터는 세그먼트 단위로 삭제가 발생하기 때문에, 로그의 한줄한줄 단위(레코드)는 개별적으로 삭제가 불가능하다. 또한 이미 적재된 데이터에 대해서 레코드의 키, 메시지 값, 오프셋, 헤더 등의 데이터는 수정이 불가능하다. -> 데이터를 적재할 때나 사용할 때, 데이터를 검증하는 것이 좋다. (**뭘 어떻게 검증 ? 문제가 없는지 라니 무슨 문제 ?)
		* cleanup.policy=compact
			* 토픽을 **압축**하는 정책 (delete 는 세그먼트 단위로 **삭제** 하는 정책)
			* 한 세그먼트 내에서 메시지 키 별로 메시지 키의 레코드 중 오래된 데이터를 삭제하는 정책.
			* 압축 시에는 영역별로 다르게 수행된다.
				* 테일 영역
					* 압축 정책에 의해 압축이 완료된 레코드들(클린)이 모여있는 곳. 클린 로그 라고도 불린다.
				* 헤드 영역
					* 압축 정책이 되기 전 레코드들로, 더티(dirty)로그 라고도 불린다. 중복된 메시지 키가 있다.
		* min.cleanable.dirty.ratio 옵션
			* 엑티브 세그먼트를 제외하고, 테일 영역의 레코드 개수와 헤드 영역의 레코드 개수의 비율에 따라서 압축을 진행한다. 
			* 0.9와 같이 크게 설정하면 한번 압축을 할 때 많은 데이터가 줄어드므로, 압축 효과가 좋다. 그러니 0.9 비율이 될 때 까지 삭제가 발생하지 않으므로, 용량 효율이 좋지 않다. 
			* 반대로 0.1 과 같이 작게 설정하면 압축이 자주 일어나서, 가장 최신 데이터만 유지할 수 있지만, 압축이 자주 발생하기 때문에 브로커에 부담이 된다. 
			* **적정한 설정 값을 설정해야 한다.** 
---
# 5. 복제

* 카프카의 데이터 복제는 카프카를 장애 허용 시스템 (fault tolerant system)으로 동작하도록 하는 원동력이다. 
* 복제를 하는 이유는 클러스터로 묶은 브로커 중 일부 브로커에 장애가 발생하더라도 데이터를 유실하지 않고 안전하게 사용하기 위함이다. 
* 복제는 **파티션 단위로 이루어진다**. 
	* 토픽을 생성할 때 파티션의 복제 개수 (replication factor)도 같이 설정되는데, 직접 옵션을 설정하지 않으면 브로커에 설정된 기본 옵션 값을 따라가게 된다. 
	* 복제 개수의 최솟값은 1(복제 없음)이고 최댓값은 브로커 개수만큼 설정하여 사용할 수 있다.
* 복제된 파티션은 리더(leader)와 팔로워(follower)로 구성된다.
	* 프로듀서 또는 컨슈머와 직접 통신하는 파티션을 리더, 나머지를 팔로워라고 부른다.
	* 팔로워 파티션들은 리더 파티션의 오프셋 정보를 확인하여 현재 자신이 가지고 있는 오프셋과 차이가 나는 경우 리더 파티션으로 부터 데이터를 가져와서 자신의 파티션에 저장하는데, 이 과정을 '**복제**'라고 한다.
* 파티션 복제로 인해 나머지 브로커에도 파티션의 데이터가 복제되므로, 복제 개수만큼 저장 용량이 비례하여 증가하는 단점이 있다.
	* 용량적은 단점에도 불구하고 카프카가 제공하는 데이터 안정성 때문에 카프카를 운용할 때에는 최소 2 이상의 복제 개수를 정하는 것이 중요하다.
	* **디스크를 사용하는 대신에 가용성을 높인다.**
* replication factor 를 1 로 설정하는 경우는 메트릭 데이터를 사용할때 정도가 있다. (유실되어도 상관 없는 경우)
---
# ISR (In-Sync-Replicas)

* ISR 은 **리터 파티션과 팔로워 파티션이 모두 싱크가 된 상태** 를 말한다.
* 복제 개수가 2인 토픽을 가정해보면,
	* 이 토픽에는 리더 파티션 1개와 팔로워 파티션 1개가 존재한다.
	* 리더 파티션에 0부터 3의 오프셋이 있다고 가정할 때, 팔로워 파티션에 동기화가 완료되려면 0부터 3 까지 오프셋이 존재해야 한다. 
	* 동기화가 완료됐다는 의미는 리더 파티션의 모든 데이터가 팔로워 파티션에 복제된 상태를 말하기 때문이다.
* **unclean.leader.election.enable** 옵션
	* 리더 파티션의 데이터를 모두 복제하지 못한 상태이고, 이렇게 싱크가 되지 않은 팔로워 파티션이 리더 파티션으로 선출되면 데이터가 유실될 수 있다.
	* 유실이 발생하더라도 서비스를 중단하지 않고 지속적으로 토픽을 사용하고 싶다면 ISR 이 아닌 팔로워 파티션을 리더로 선출하도록 설정할 수 있다.
		* true : 유실을 감수함. 복제가 안된 팔로워 파티션을 리더로 승급.
		* false : 유실을 감수하지 않음. 해당 브로커가 복구될 때 까지 중단.
	* 토픽별로 설정이 가능하기 때문에, 유실되면 안되는 데이터 vs 24시간 365일 수집되는 데이터 등 **데이터의 성격에 따라서 옵션 값을 다르게 설정**한다.
---
# 6. 토픽과 파티션

* **토픽**은 카프카에서 데이터를 구분하기 위해 사용하는 단위이다.
* 토픽은 최소한 1개 이상의 **파티션**을 소유하고 있다.
	* 파티션에는 프로듀서가 보낸 데이터들이 저장되는데, 이 데이터를 **레코드(record)**라고 부른다. (레코드는 메시지 키와 메시지 값으로 구성되어 있다.)
	* 파티션은 큐(queue)와 비슷한 구조이다. (FIFO)
		* 먼저 들어간 데이터가 먼저 소모된다.
	* 일반적인 자료구조 queue 는 데이터가 사용되면(pop) 삭제되지만, 카프카는 삭제하지 않는다.
	* 이러한 특징 때문에 토픽의 레코드는 다양한 목적을 가진 여러 컨슈머 그룹들이 토픽의 데이터를 여러번 가져갈 수 있다.
* 토픽 생성 시 파티션이 배치되는 방법
![[2-5.png]]
* 파티션이 5개인 토픽을 생성하는 경우, 위 그림과 같이 0번 브로커부터 시작하여 **round-robin 방식**으로 리더 파티션들이 생성된다. 
* 카프카 클라이언트는 리더 파티션이 있는 브로커와 통신하여 데이터를 주고 받으므로, 여러 브로커에 골고루 네트워크 통신을 하게 된다. 이를 통해 데이터가 특정 서버와 통신이 집중되는 현상을 막고, 선형 확장을 하여 데이터가 많아지더라도 자연스럽게 대응할 수 있다.
![[2-6.png]]
* 위와 같이 리더 파티션이 특정 브로커에 몰려있는 경우, 0번 브로커의 서버 자원 사용률이 높아질 수 있다. 
* 이럴때는 kafka-reassign-partitions.sh 쉘 파일을 실행해서 파티션을 재분배할 수 있다.
### 파티션 개수와 컨슈머 개수의 처리량

* 파티션은 카프카의 병렬 처리의 핵심으로써 그룹으로 묶인 컨슈머들이 레코드를 병렬로 처리할 수 있도록 매칭된다.
* 컨슈머의 처리량이 한정된 상황에서 많은 레코드를 병렬로 처리하는 가장 좋은 방법은 컨슈머의 개수를 늘려 스케일 아웃하는 것이다.
* 컨슈머를 늘리면서 파티션도 늘리면 처리량이 증가하는 효과를 볼 수 있다.
* 파티션과 컨슈머 개수 관련 설정은 초당 쌓이는 데이터 대비 살짝 넉넉하게 설정한다.
	* 1초에 10개의 데이터가 토픽에 쌓이는 경우
	* 파티션 개수와 컨슈머 개수를 20개 정도씩 설정하는 것이 일반적이다.

### 파티션의 개수를 줄이는건 불가능하다

* 카프카는 파티션의 개수를 줄이는 것은 지원하지 않는다. 
* 파티션을 늘리는 작업을 할 때는 신중히 파티션 개수를 정해야 한다.
	* 토픽을 삭제하고 재생성하는 방법 밖에 없다.
---
# 7. 레코드
![[2-7.png]]
* 레코드는 타임스탬프, 헤더, 메시지 키, 메시지 값, 오프셋 으로 구성되어 있다.
* 브로커에 한번 적재된 레코드는 수정할 수 없고, **로그 리텐션 기간** 또는 **용량**에 따라서만 삭제된다.
#### 레코드 - 타임스탬프
* 타임스탬프는 스트림 프로세싱에서 활용하기 위한 시간을 저장하는 용도로 사용된다.
#### 레코드 - 오프셋
* 오프셋은 프로듀서가 생성한 레코드에는 존재하지 않는다. 
* 오프셋은 프로듀서가 전송한 레코드가 **브로커에 적재될 때 생성된다**.
* 오프셋은 0부터 시작되며 1씩 증가한다.
* 컨슈머는 오프셋을 기반으로 처리가 완료된 데이터와 앞으로 처리해야할 데이터를 구분한다.
* 각 메시지별로 고유한 오프셋을 가지므로 컨슈머에서 중복 처리를 방지하기 위한 목적으로도 사용한다.
#### 레코드 - 헤더
* 헤더는 0.11부터 제공된 기능이다.
* http 통신의 헤더와 비슷한 역할을 한다.
* key/value  데이터를 추가할 수 있으며, 레코드의 스미카 버전이나 포맷과 같이 데이터 프로세싱에 참고할만한 정보를 담아서 사용할 수 있다.
#### 레코드 - 키
* 메시지 키는 처리하고자 하는 메시지 값을 분류하기 위한 용도로 사용된다. (파티셔닝)
* 파티셔닝에 사용하는 메시지 키는 파티셔너에 따라 토픽의 파티션 번호가 정해진다.
* 메시지 키는 필수 값이 아니며, 지정하지 않으면 null로 설정된다.
* 메시지 키가 null 인 레코드는 특정 토픽의 파티션에 라운드 로빈으로 전달된다.
* null 이 아닌 메시지 키는 해쉬값에 의해서 특정 파티션에 매핑되어 전달된다. (기본 파티셔너의 경우)
* 레코드 키를 활용하여 순서가 보장된 토픽을 구현한다.
#### 레코드 - 값
* 실질적으로 처리할 데이터가 담기는 공간이다. 
* 다양한 형태로 지정 가능하며 필요에 따라 사용자 지정 포맷으로 직렬화/역직렬화 클래스를 만들어 사용할 수도 있다.
* 주로 **json 형태**로 활용한다.
---
# 8. 유지보수하기 좋은 토픽 이름 정하기

### 기본 제약조건

1. 빈 문자열 토픽 이름은 지원하지 않는다. 
2. 토픽 이름은 마침표 하나(.) 또는 마침표 둘(..)로 생성될 수 없다.
3. 영어 대, 소문자, 숫자 0 ~ 9, 마침표, 언더바, 하이픈 조합으로 생성할 수 있다. (이외의 문자열이 포함된 토픽은 생성 불가하다.)
4. 내부 로직 관리용 토픽과 같은 이름은 생성 불가하다.
	1. consumer_offsets
	2. transaction_state
5. 카프카 내부 로직 때문에, 토픽 이름에 마침표와 언더바가 동시에 들어가면 안된다.
###  이름 작명법

* 토픽 이름을 모호하게 작성하지 않는다.
* 개발팀 내부적으로 토픽 작명 Rule 을 문서화 하여 관리한다.
* 작명 예시
	* <환경>.<팀-명>.<어플리케이션-명>.<메시지-타입>
		* prd.marketing-team.sms-platform.json
	* <프로젝트-명>.<서비스-명>.<환경>.<이벤트-명>
		* commerce.payment.prd.notification
	* <환경>.<서비스-명>.<JIRA-번호>.<메시지-타입>
		* dev.email-sender.jira-1234.email-vo-custom
	* <카프카-클러스터명>.<환경>.<서비스-명>.<메시지-타입>
		* aws-kafka.live.marketing-platform.json
---
# 9. 브로커와 클라이언트의 통신

* 클라이언트(프로듀서/컨슈머)는 브로커에 meta-data 를 요청하고 응답을 받는다.
	* meta-data는 리더 파티션의 위치 정보를 담고 있다.
	* 각 클라이언트는 리더 파티션과 통신을 하게 된다.
* 프로듀서 메타데이터 옵션
	* metadata.max.age.ms : 메타데이터를 강제로 리프레시하는 간격 (기본값 5분)
	* metadata.max.idle.ms : 프로듀서가 유휴상태일 경우 메타데이터를 캐시야 유지하는 기간. (기본값 5분)
* 클라이언트의 메타데이터가 이슈가 발생한 경우
	* 메타데이터가 실제 브로커 상태와 불일치가 발생된 상태에서 데이터를 브로커에 요청하면, LEADER_NOT_AVAILABLE 익셉션이 발생한다.
	* 대부분이 메타데이터 리프래시 이슈로 발생한다.
	* 위 에러가 자주 발생하는 경우, 메타데이터 리프래시 간격을 확인하고 클라이언트가 정상적인 메타데이터를 갖고 있는지 확인해봐야 한다.